{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-04-15_21-08-10_13968/logs.\n",
      "Waiting for redis server at 127.0.0.1:38368 to respond...\n",
      "Waiting for redis server at 127.0.0.1:38475 to respond...\n",
      "Starting Redis shard with 10.0 GB max memory.\n",
      "WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 3818061824 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "Starting the Plasma object store with 4.0 GB memory using /tmp.\n"
     ]
    }
   ],
   "source": [
    "#Imports necessários\n",
    "import numpy as np\n",
    "import modin.pandas as pds\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "from pandas import concat\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "#Analise do dataset\n",
    "data = pds.read_csv('dataset_prediction.csv')\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analise do dataset\n",
    "data = pds.read_csv('dataset_prediction.csv')\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlação de atributos\n",
    "corrData = data.copy()\n",
    "df_corr = corrData.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "#Dados de locacao de dia de semana por fim de semana\n",
    "data.groupby(['is_weekend'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "#Dados de locacao por clima (chuva ou neve)\n",
    "data.groupby(['rain_or_snow'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de locacao por clima nublado\n",
    "data.groupby(['tstorms'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de locacao por clima nublado\n",
    "data.groupby(['cloudy'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.groupby(['month'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.groupby(['year'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['hour'])['rentals'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "#Pre-Processamento dos dados\n",
    "\n",
    "#Normalizacao\n",
    "data.year = preprocessing.scale(list(data.year))\n",
    "data.month = preprocessing.scale(list(data.month))\n",
    "data.week = preprocessing.scale(list(data.week))\n",
    "data.day = preprocessing.scale(list(data.day))\n",
    "data.hour = preprocessing.scale(list(data.hour))\n",
    "data.mean_temperature = preprocessing.scale(list(data.mean_temperature))\n",
    "data.median_temperature = preprocessing.scale(list(data.median_temperature))\n",
    "\n",
    "#Visualização dos dados\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processamento dos dados\n",
    "\n",
    "#Normalizacao\n",
    "data.year = preprocessing.scale(list(data.year))\n",
    "data.month = preprocessing.scale(list(data.month))\n",
    "data.week = preprocessing.scale(list(data.week))\n",
    "data.day = preprocessing.scale(list(data.day))\n",
    "data.hour = preprocessing.scale(list(data.hour))\n",
    "data.mean_temperature = preprocessing.scale(list(data.mean_temperature))\n",
    "data.median_temperature = preprocessing.scale(list(data.median_temperature))\n",
    "\n",
    "#Visualização dos dados\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificacao de dados do dataset\n",
    "collections.Counter(data.is_weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelos a serem testados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "\n",
    "#Retirada da variável target das features de predição\n",
    "X = data.drop('rentals',1)\n",
    "y = data.rentals\n",
    "\n",
    "#Separação de conjunto de testes\n",
    "X_model, X_test, y_model, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \n",
    "\n",
    "#Separação de conjunto de validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "#Treinamento de modelos \n",
    "lr = LinearRegression(n_jobs=5, fit_intercept=True)\n",
    "logr = LogisticRegression(penalty='l2', C=1.0, fit_intercept=True, random_state=0, solver='liblinear', n_jobs=5)\n",
    "dt = DecisionTreeRegressor(max_depth=10, criterion='mse', splitter='best', random_state=0, presort=True)\n",
    "dtr = AdaBoostRegressor(dt,n_estimators=500, learning_rate=0.1, random_state=0)\n",
    "rf = RandomForestRegressor(n_estimators=100, criterion='mse', max_features='auto', random_state=0, n_jobs=5)\n",
    "blr = BayesianRidge(n_iter=1000, fit_intercept=True)\n",
    "\n",
    "#Criacao de vetor de modelos\n",
    "algs = []\n",
    "algs.append(lr)\n",
    "algs.append(logr)\n",
    "algs.append(dt)\n",
    "algs.append(dtr)\n",
    "algs.append(rf)\n",
    "algs.append(blr)\n",
    "\n",
    "#Fit dos modelos\n",
    "for alg in algs:\n",
    "    print('Fitting: ', type(alg).__name__)\n",
    "    alg.fit(X_model, y_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento de modelos \n",
    "lr = LinearRegression(n_jobs=5, fit_intercept=True)\n",
    "logr = LogisticRegression(penalty='l2', C=1.0, fit_intercept=True, random_state=0, solver='liblinear', n_jobs=5)\n",
    "dt = DecisionTreeRegressor(max_depth=10, criterion='mse', splitter='best', random_state=0, presort=True)\n",
    "dtr = AdaBoostRegressor(dt,n_estimators=500, learning_rate=0.1, random_state=0)\n",
    "rf = RandomForestRegressor(n_estimators=100, criterion='mse', max_features='auto', random_state=0, n_jobs=5)\n",
    "blr = BayesianRidge(n_iter=1000, fit_intercept=True)\n",
    "\n",
    "#Criacao de vetor de modelos\n",
    "algs = []\n",
    "algs.append(lr)\n",
    "algs.append(logr)\n",
    "algs.append(dt)\n",
    "algs.append(dtr)\n",
    "algs.append(rf)\n",
    "algs.append(blr)\n",
    "\n",
    "#Fit dos modelos\n",
    "for alg in algs:\n",
    "    print('Fitting: ', type(alg).__name__)\n",
    "    alg.fit(X_model, y_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição de dataframe para exibição de resultados\n",
    "results = pds.DataFrame(columns=['Name', 'Type', 'R2', 'MAE', 'MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para display de resultados\n",
    "def appendResult(alg, dataType, X, y):\n",
    "    algName = type(alg).__name__\n",
    "    predicted = alg.predict(X)\n",
    "    mae = mean_absolute_error(y, predicted)\n",
    "    mse = mean_squared_error(y, predicted)\n",
    "    r2 = r2_score(y, predicted)\n",
    "    results.loc[len(results)]=[algName, dataType, r2, mae, mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento\n",
    "for alg in algs:\n",
    "    appendResult(alg, 'Train', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validação do treinamento\n",
    "for alg in algs:\n",
    "    appendResult(alg, 'Validation', X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste final\n",
    "for alg in algs:\n",
    "    appendResult(alg, 'Test', X_test, y_test)\n",
    "    \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
